# Release Notes - GoLLM v0.6.0

**Release Date:** 2025-12-14
**Base Version:** v0.5.1 (commit d8763ee)

## üéâ Overview

Version 0.6.0 is a major feature release that adds X.AI Grok provider support, implements Anthropic streaming, introduces comprehensive testing infrastructure, and enhances the canonical response structure to preserve provider-specific metadata.

**Summary:**
- ‚ú® New X.AI Grok provider with full streaming support
- ‚ú® Complete Anthropic streaming implementation
- üß™ Comprehensive test suite with 44 tests (unit + integration)
- üìä Provider metadata preservation in responses
- üèóÔ∏è Mock infrastructure for testing
- üìö Enhanced documentation and examples
- üîß Code quality improvements

**Statistics:**
- **Files Changed:** 22 files
- **Lines Added:** 3,041 insertions
- **Lines Removed:** 61 deletions
- **New Files:** 12 files
- **Test Coverage:** 44 automated tests

---

## ‚ú® New Features

### 1. X.AI Grok Provider Support

Complete implementation of X.AI's Grok API with OpenAI-compatible interface.

**New Files:**
- `providers/xai/xai.go` - HTTP client with SSE streaming (204 lines)
- `providers/xai/types.go` - Request/response types (68 lines)
- `providers/xai/adapter.go` - Provider interface implementation (159 lines)
- `providers/xai/integration_test.go` - Integration tests (181 lines)
- `examples/xai/main.go` - Usage examples (161 lines)

**Supported Models:**

**Grok 4.1 (Latest - November 2025):**
- `grok-4-1-fast-reasoning` - Best tool-calling model with 2M context window
- `grok-4-1-fast-non-reasoning` - Instant responses with 2M context window

**Grok 4 (July 2025):**
- `grok-4-0709` - Flagship model with 256K context
- `grok-4-fast-reasoning` - Fast reasoning with 2M context
- `grok-4-fast-non-reasoning` - Fast non-reasoning with 2M context
- `grok-code-fast-1` - Coding-optimized model with 256K context

**Grok 3:**
- `grok-3` - Grok 3 model
- `grok-3-mini` - Smaller, faster variant

**Grok 2:**
- `grok-2-1212` - Grok 2 (December 2024)
- `grok-2-vision-1212` - Grok 2 with vision capabilities

**Example Usage:**
```go
client, err := gollm.NewClient(gollm.ClientConfig{
    Provider: gollm.ProviderNameXAI,
    APIKey:   os.Getenv("XAI_API_KEY"),
})
```

**Constants Added:**
- `ProviderNameXAI` - Provider identifier
- `EnvVarXAIAPIKey` - Environment variable constant
- Grok 4.1 Models: `ModelGrok4_1FastReasoning`, `ModelGrok4_1FastNonReasoning`
- Grok 4 Models: `ModelGrok4_0709`, `ModelGrok4FastReasoning`, `ModelGrok4FastNonReasoning`, `ModelGrokCodeFast1`
- Grok 3 Models: `ModelGrok3`, `ModelGrok3Mini`
- Grok 2 Models: `ModelGrok2_1212`, `ModelGrok2_Vision`

### 2. Anthropic Streaming Implementation

Full native streaming support for Anthropic Claude using Server-Sent Events (SSE).

**Files Modified:**
- `providers/anthropic/anthropic.go` - Added SSE streaming client (+126 lines)
- `providers/anthropic/adapter.go` - Streaming adapter implementation (+174 lines)
- `providers/anthropic/types.go` - Streaming event types (+32 lines)

**New Streaming Types:**
- `StreamEvent` - SSE event container
- `StreamDelta` - Delta content for streaming
- `StreamMessage` - Message metadata
- `StreamUsage` - Streaming usage information

**Example:**
```go
stream, err := client.CreateChatCompletionStream(ctx, &gollm.ChatCompletionRequest{
    Model: gollm.ModelClaude3Sonnet,
    Messages: []gollm.Message{
        {Role: gollm.RoleUser, Content: "Write a haiku"},
    },
})
defer stream.Close()

for {
    chunk, err := stream.Recv()
    if err == io.EOF {
        break
    }
    if len(chunk.Choices) > 0 && chunk.Choices[0].Delta != nil {
        fmt.Print(chunk.Choices[0].Delta.Content)
    }
}
```

**Example Added:**
- `examples/anthropic_streaming/main.go` - Complete streaming demonstrations (158 lines)

### 3. Provider Metadata Preservation

New `ProviderMetadata` field in response structures to preserve provider-specific information.

**Files Modified:**
- `provider/types.go` - Added `ProviderMetadata map[string]any` to:
  - `ChatCompletionResponse` (line 74)
  - `ChatCompletionChunk` (line 102)

**Anthropic Metadata Preserved:**
- `anthropic_type` - Response type
- `anthropic_role` - Response role
- `anthropic_content` - Full content array (preserves multi-block responses)
- `anthropic_stop_reason` - Stop reason
- `anthropic_event_type` - Streaming event types
- `anthropic_delta` - Delta objects
- `anthropic_usage` - Usage information

**Example Usage:**
```go
response, err := client.CreateChatCompletion(ctx, req)

// Access standard unified fields
content := response.Choices[0].Message.Content

// Access Anthropic-specific metadata
if metadata := response.ProviderMetadata; metadata != nil {
    if fullContent, ok := metadata["anthropic_content"].([]anthropic.Content); ok {
        // Access all content blocks, not just first
        for _, block := range fullContent {
            fmt.Printf("Block [%s]: %s\n", block.Type, block.Text)
        }
    }
}
```

**Benefits:**
- ‚úÖ Backward compatible - existing code continues working
- ‚úÖ Provider-agnostic - any provider can add metadata
- ‚úÖ No data loss - preserves full provider responses
- ‚úÖ Optional - field omitted when empty

### 4. Comprehensive Testing Infrastructure

Complete test suite with unit tests, integration tests, and mock implementations.

**New Test Files:**
- `client_test.go` - Client and memory integration tests (441 lines)
- `memory_test.go` - Conversation memory tests (314 lines)
- `providers/anthropic/adapter_test.go` - Anthropic unit tests (270 lines)
- `providers/anthropic/integration_test.go` - Anthropic API tests (302 lines)
- `providers/openai/integration_test.go` - OpenAI API tests (181 lines)
- `providers/xai/integration_test.go` - X.AI API tests (181 lines)
- `testing/mock_kvs.go` - Mock KVS implementation (102 lines)

**Test Statistics:**
- **Total Tests:** 44 automated tests
- **Unit Tests:** ~30 tests (run without API keys)
- **Integration Tests:** ~14 tests (conditional on API keys)

**Test Categories:**

1. **Client Tests** (`client_test.go`)
   - Client creation and configuration
   - Chat completion (sync and streaming)
   - Memory-aware completions
   - Conversation management
   - Provider injection

2. **Memory Tests** (`memory_test.go`)
   - Load/save conversations
   - Append messages
   - Max message limits
   - System message preservation
   - Metadata handling
   - Conversation deletion

3. **Provider Tests** (Anthropic, OpenAI, X.AI)
   - Message conversion
   - Request/response mapping
   - Streaming adapters
   - Error handling
   - Real API integration (conditional)

**Integration Test Pattern:**
```go
func TestAnthropicIntegration_Streaming(t *testing.T) {
    apiKey := os.Getenv("ANTHROPIC_API_KEY")
    if apiKey == "" {
        t.Skip("Skipping integration test: ANTHROPIC_API_KEY not set")
    }
    // Test actual API calls...
}
```

**Running Tests:**
```bash
# Run all unit tests (no API keys required)
go test ./... -short

# Run with coverage
go test ./... -short -cover

# Run integration tests (requires API keys)
ANTHROPIC_API_KEY=key go test ./providers/anthropic -v
OPENAI_API_KEY=key go test ./providers/openai -v
XAI_API_KEY=key go test ./providers/xai -v
```

**Mock Infrastructure:**
- `testing/mock_kvs.go` - In-memory KVS for testing conversation memory without external dependencies
- Mock providers for unit testing client logic

---

## üîß Improvements

### Code Quality

1. **Type Modernization**
   - Replaced `interface{}` with `any` throughout codebase
   - Updated in `provider/types.go`, `client.go`, `providers/anthropic/adapter.go`
   - Improves readability and follows Go 1.18+ conventions

2. **Lint Fixes**
   - Fixed all `golangci-lint` issues
   - Removed ineffectual assignments
   - Removed unused struct fields
   - Fixed `gofmt` issues
   - **Result:** 0 lint issues

3. **Memory Function Improvements**
   - Updated `memory.go` with better type safety (18 lines modified)

4. **X.AI Grok 4 Model Support** ‚≠ê NEW
   - Added 6 new Grok 4/4.1 model constants
   - Grok 4.1 Fast: Latest with 2M context window and tool calling
   - Grok 4 Fast: 2M context with reasoning/non-reasoning modes
   - Grok Code Fast: Optimized for coding tasks (256K context)
   - Updated examples and tests to use `grok-4-1-fast-reasoning`

### Documentation

1. **README.md Updates** (166 lines modified)
   - Added X.AI provider documentation
   - Updated architecture diagram with `xai/` provider
   - Added comprehensive Testing section
   - Updated model listings for all providers:
     - OpenAI: Added GPT-5, GPT-4.1 models
     - Anthropic: Added Claude-Opus-4.1, Claude-Opus-4, Claude-Sonnet-4, Claude-3.7-Sonnet, Claude-3.5-Haiku
     - Gemini: Updated to current models
   - Enhanced Contributing section with test requirements
   - Added integration test examples with X.AI

2. **Provider Support Table Updated**
   ```
   | Provider   | Models                           | Features                          |
   |------------|----------------------------------|-----------------------------------|
   | OpenAI     | GPT-5, GPT-4.1, GPT-4o, ...     | Chat, Streaming, Functions        |
   | Anthropic  | Claude-Opus-4.1, Sonnet-4, ...  | Chat, Streaming, System messages  |
   | Gemini     | Gemini-2.5-Pro, 2.5-Flash, ...  | Chat, Streaming                   |
   | Bedrock    | Claude models, Titan models      | Chat, Multiple model families     |
   | X.AI       | Grok-4.1-Fast, Grok-4, Grok-4-Fast, Grok-Code-Fast, Grok-3, Grok-2 | Chat, Streaming, 2M context, Tool calling |
   | Ollama     | Llama 3, Mistral, Gemma, ...    | Chat, Streaming, Local inference  |
   ```

3. **New Examples**
   - `examples/anthropic_streaming/main.go` - 3 Anthropic streaming scenarios
   - `examples/xai/main.go` - 3 X.AI usage examples

---

## üìä Statistics

### Code Additions by Component

| Component                  | Lines Added | Description                          |
|---------------------------|-------------|--------------------------------------|
| X.AI Provider             | 612         | Complete provider implementation     |
| Anthropic Streaming       | 332         | Native SSE streaming support         |
| Test Infrastructure       | 1,689       | Unit + integration + mock tests      |
| Examples                  | 319         | Usage demonstrations                 |
| Documentation             | 166         | README and inline docs               |
| **Total**                 | **3,041**   | Net additions to codebase            |

### File Distribution

- **Provider Code:** 7 files (612 lines for X.AI, 332 for Anthropic streaming)
- **Tests:** 6 files (1,689 lines)
- **Examples:** 2 files (319 lines)
- **Core Changes:** 5 files (provider/types.go, client.go, constants.go, providers.go, memory.go)
- **Mock Infrastructure:** 1 file (102 lines)

---

## üîÑ Breaking Changes

**None** - This release is fully backward compatible.

All changes are additive:
- New provider (X.AI) doesn't affect existing providers
- `ProviderMetadata` field is optional (`omitempty`)
- Existing APIs unchanged
- Test additions don't affect runtime behavior

---

## üêõ Bug Fixes

1. **Anthropic Streaming**
   - Previously unimplemented streaming now fully functional
   - Proper SSE parsing with event type handling
   - Correct message assembly from multiple events

2. **Lint Issues**
   - Fixed ineffectual assignment in `anthropic/anthropic.go:189`
   - Removed unused field `streamChunkIndex` in `client_test.go:20`

3. **Model Updates**
   - Updated X.AI examples and tests to use latest `grok-4-1-fast-reasoning` model
   - Added support for Grok 4 and Grok 4.1 model families (6 new model constants)
   - Added deprecation markers for `grok-beta` and `grok-vision-beta`

---

## üöÄ Migration Guide

### Upgrading from v0.5.1

No code changes required - simply update your dependency:

```bash
go get -u github.com/grokify/gollm@v0.6.0
```

### Using New Features

**1. Add X.AI Grok Support:**
```go
client, err := gollm.NewClient(gollm.ClientConfig{
    Provider: gollm.ProviderNameXAI,
    APIKey:   os.Getenv("XAI_API_KEY"),
})
```

**2. Use Anthropic Streaming:**
```go
stream, err := client.CreateChatCompletionStream(ctx, &gollm.ChatCompletionRequest{
    Model: gollm.ModelClaude3Sonnet,
    Messages: []gollm.Message{
        {Role: gollm.RoleUser, Content: "Hello!"},
    },
})
```

**3. Access Provider Metadata:**
```go
response, err := client.CreateChatCompletion(ctx, req)
if metadata := response.ProviderMetadata; metadata != nil {
    // Access provider-specific data
    fmt.Printf("Metadata: %+v\n", metadata)
}
```

**4. Run Tests:**
```bash
# Unit tests only
go test ./... -short

# Integration tests (requires API keys)
export ANTHROPIC_API_KEY=your-key
export OPENAI_API_KEY=your-key
export XAI_API_KEY=your-key
go test ./... -v
```

---

## üìù Commits Since v0.5.1

```
b9ed829 style: `any`: update from `interface{}`
a509740 feat: `provider`: add `ChatCompletionChunk.ProviderMetadata`
803e5bb docs: `README.md`: update
0c438f0 chore(lint): `golangci-lint`: fix various
65917c8 feat: `providers/xai`: add support for xAI
f21d267 chore(lint): `golangci-lint`: fix `gofmt`
6fd5654 chore(lint): `golangci-lint`: fix `gofmt`
536d73c docs: `README.md`: update for Anthropic streaming
6514343 tests: add
5f430f5 feat: `providers/anthropic`: add streaming support
```

---

## üôè Acknowledgments

This release represents a significant expansion of GoLLM's capabilities with:
- Complete X.AI Grok provider integration
- Production-ready Anthropic streaming
- Enterprise-grade test coverage
- Enhanced metadata preservation

---

## üìö Resources

- **Documentation:** [README.md](README.md)
- **Examples:** See `/examples` directory
- **Tests:** Run `go test ./... -v` to see all test scenarios
- **Issues:** [GitHub Issues](https://github.com/grokify/gollm/issues)

---

**Full Changelog:** [v0.5.1...v0.6.0](https://github.com/grokify/gollm/compare/d8763ee...HEAD)
