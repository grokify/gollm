package main

import (
	"fmt"
	"log"

	"github.com/grokify/fluxllm"
)

func main() {
	fmt.Println("=== FluxLLM Provider Architecture Demo ===")
	fmt.Println()

	// Show the current architecture
	fmt.Println("Current Architecture:")
	fmt.Println("ğŸ“ fluxllm/ (main package)")
	fmt.Println("  â”œâ”€â”€ client.go        - ChatClient wrapper")
	fmt.Println("  â”œâ”€â”€ provider.go      - Provider interface")
	fmt.Println("  â”œâ”€â”€ providers.go     - Provider adapters")
	fmt.Println("  â”œâ”€â”€ types.go         - Unified types")
	fmt.Println("  â”œâ”€â”€ errors.go        - Error handling")
	fmt.Println("  â””â”€â”€ providers/")
	fmt.Println("      â”œâ”€â”€ openai/      - OpenAI implementation")
	fmt.Println("      â”œâ”€â”€ anthropic/   - Claude implementation")
	fmt.Println("      â”œâ”€â”€ bedrock/     - AWS Bedrock implementation")
	fmt.Println("      â””â”€â”€ ollama/      - Ollama local models")
	fmt.Println()

	// Demonstrate creating clients for different providers
	fmt.Println("Creating clients for different providers...")

	// OpenAI client (won't work without real API key)
	openaiClient, err := fluxllm.NewClient(fluxllm.ClientConfig{
		Provider: fluxllm.ProviderNameOpenAI,
		APIKey:   "demo-openai-key",
	})
	if err != nil {
		log.Printf("Failed to create OpenAI client: %v", err)
	} else {
		fmt.Printf("âœ… OpenAI client created: %s\n", openaiClient.Provider().Name())
		openaiClient.Close()
	}

	// Anthropic client (won't work without real API key)
	anthropicClient, err := fluxllm.NewClient(fluxllm.ClientConfig{
		Provider: fluxllm.ProviderNameAnthropic,
		APIKey:   "demo-anthropic-key",
	})
	if err != nil {
		log.Printf("Failed to create Anthropic client: %v", err)
	} else {
		fmt.Printf("âœ… Anthropic client created: %s\n", anthropicClient.Provider().Name())
		anthropicClient.Close()
	}

	// Bedrock client (requires AWS credentials)
	bedrockClient, err := fluxllm.NewClient(fluxllm.ClientConfig{
		Provider: fluxllm.ProviderNameBedrock,
		Region:   "us-east-1",
	})
	if err != nil {
		log.Printf("âš ï¸  Bedrock client creation failed (expected without AWS creds): %v", err)
	} else {
		fmt.Printf("âœ… Bedrock client created: %s\n", bedrockClient.Provider().Name())
		bedrockClient.Close()
	}

	// Ollama client (works locally, no credentials needed)
	ollamaClient, err := fluxllm.NewClient(fluxllm.ClientConfig{
		Provider: fluxllm.ProviderNameOllama,
		BaseURL:  "http://localhost:11434",
	})
	if err != nil {
		log.Printf("âš ï¸  Ollama client creation failed (is Ollama running?): %v", err)
	} else {
		fmt.Printf("âœ… Ollama client created: %s\n", ollamaClient.Provider().Name())
		ollamaClient.Close()
	}

	fmt.Println()
	fmt.Println("Benefits of this architecture:")
	fmt.Println("1. ğŸ”Œ Pluggable: Easy to add new LLM providers")
	fmt.Println("2. ğŸ¯ Unified: Same API for all providers")
	fmt.Println("3. ğŸ§ª Testable: Provider interface can be mocked")
	fmt.Println("4. ğŸ“¦ Modular: Each provider is self-contained")
	fmt.Println("5. ğŸ”§ Maintainable: Clear separation of concerns")
	fmt.Println("6. ğŸ  Local + Cloud: Mix local (Ollama) and cloud providers")

	// Show example request structure
	fmt.Println()
	fmt.Println("Example unified request structure:")
	fmt.Println("Cloud model example:")
	cloudReq := &fluxllm.ChatCompletionRequest{
		Model: fluxllm.ModelGPT4o, // OpenAI cloud model
		Messages: []fluxllm.Message{
			{Role: fluxllm.RoleSystem, Content: "You are a helpful assistant."},
			{Role: fluxllm.RoleUser, Content: "Hello, world!"},
		},
		MaxTokens:   &[]int{100}[0],
		Temperature: &[]float64{0.7}[0],
	}
	fmt.Printf("  Model: %s (OpenAI)\n", cloudReq.Model)

	fmt.Println()
	fmt.Println("Local model example:")
	localReq := &fluxllm.ChatCompletionRequest{
		Model: "llama3", // Ollama local model
		Messages: []fluxllm.Message{
			{Role: fluxllm.RoleSystem, Content: "You are a helpful assistant."},
			{Role: fluxllm.RoleUser, Content: "Hello, world!"},
		},
		MaxTokens:   &[]int{100}[0],
		Temperature: &[]float64{0.7}[0],
	}
	fmt.Printf("  Model: %s (Ollama)\n", localReq.Model)

	fmt.Println()
	fmt.Println("ğŸ‰ The same request structure works with ALL providers!")
	fmt.Println("   Switch from cloud to local by just changing the client config!")
}
